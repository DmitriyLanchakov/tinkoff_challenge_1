{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd;\n",
    "import random\n",
    "import numpy as np;\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_test = 'data/credit_test.csv'\n",
    "path_train = 'data/credit_train.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#надеюсь в следующий раз огранизаторы предоставят данные в нормальной кодировке\n",
    "test = pd.read_csv(path_test,sep =  ';',encoding = \"cp1251\")\n",
    "train = pd.read_csv(path_train,sep =  ';',encoding = \"cp1251\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train['test'] = 0\n",
    "test['test'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#ссоединяем test и train, чтобы одновременно их обрабатывать\n",
    "data = pd.DataFrame()\n",
    "data = train.copy()\n",
    "test['open_account_flg'] = -1\n",
    "data = data.append(test, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data['sex'] = (data['gender'] == 'M').astype(np.int8)\n",
    "del data['gender']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "для всех номинальных признаков юзаем One-hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['m_UNM'] = (data['marital_status'] == 'UNM').astype(np.int8)\n",
    "data['m_DIV'] = (data['marital_status'] == 'DIV').astype(np.int8)\n",
    "data['m_MAR'] = (data['marital_status'] == 'MAR').astype(np.int8)\n",
    "data['m_WID'] = (data['marital_status'] == 'WID').astype(np.int8)\n",
    "data['m_CIV'] = (data['marital_status'] == 'CIV').astype(np.int8)\n",
    "del data['marital_status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#работа, причем в данных оказалось на несколько позиций больше, чем было в описании \n",
    "data['j_SPC'] = (data['job_position'] == 'SPC').astype(np.int8)\n",
    "data['j_UMN'] = (data['job_position'] == 'UMN').astype(np.int8)\n",
    "data['j_BIS'] = (data['job_position'] == 'BIS').astype(np.int8)\n",
    "data['j_PNA'] = (data['job_position'] == 'PNA').astype(np.int8)\n",
    "data['j_DIR'] = (data['job_position'] == 'DIR').astype(np.int8)\n",
    "data['j_ATP'] = (data['job_position'] == 'ATP').astype(np.int8)\n",
    "data['j_WRK'] = (data['job_position'] == 'WRK').astype(np.int8)\n",
    "data['j_NOR'] = (data['job_position'] == 'NOR').astype(np.int8)\n",
    "data['j_WOI'] = (data['job_position'] == 'WOI').astype(np.int8)\n",
    "data['j_INP'] = (data['job_position'] == 'INP').astype(np.int8)\n",
    "data['j_other'] = data['job_position'].isin(['BIU','WRP','PNI','PNV','HSK','PNS','INV','ONB'])\n",
    "data['j_other'] = data['j_other'].astype(np.int8)\n",
    "del data ['job_position']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#образование \n",
    "data['e_SCH'] = (data['education'] == 'SCH').astype(np.int8)\n",
    "data['e_PGR'] = (data['education'] == 'PGR').astype(np.int8)\n",
    "data['e_GRD'] = (data['education'] == 'GRD').astype(np.int8)\n",
    "data['e_UGR'] = (data['education'] == 'UGR').astype(np.int8)\n",
    "data['e_ACD'] = (data['education'] == 'ACD').astype(np.int8)\n",
    "del data['education']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#бинаризуем тариф \n",
    "#до 1.26 тарифа норм, а остальное мелочь \n",
    "tariff = data['tariff_id'].value_counts().index[:-8]\n",
    "for i in tariff:\n",
    "    a = 't_' + str(i)\n",
    "    data[a] = (data['tariff_id'] == i).astype(np.int8)\n",
    "data['t_other'] = False\n",
    "data.loc[(data[data['tariff_id'].isin(data['tariff_id'].value_counts().index[-8:])]['t_other'] == True).index,'t_other'] = True\n",
    "data['t_other'] = data['t_other'].astype(np.int8)\n",
    "del data['tariff_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#преобразуем credit_sum в int, также добавим колонку частотности признака\n",
    "data['credit_sum'] = data['credit_sum'].apply(lambda x: float(x.replace(',', '.')))\n",
    "credit_sum_freq = data['credit_sum'].value_counts(normalize=True).to_dict()\n",
    "data['credit_sum_Freq'] = data['credit_sum'].apply(lambda x: credit_sum_freq[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#т.к кредит не наличкой, а на покупку вещи, то добавим признаки\n",
    "# на что заканчивается цена покупки\n",
    "data['is_990'] = (data['credit_sum'] % 1000 == 990).astype(np.int8)\n",
    "data['is_int'] = (data['credit_sum'] % 1 == 0).astype(np.int8)\n",
    "data['is_89'] = (data['credit_sum'] % 100 == 89).astype(np.int8)\n",
    "data['is_68'] = (data['credit_sum'] % 100 == 68).astype(np.int8)\n",
    "data['is_69'] = (data['credit_sum'] % 100 == 69).astype(np.int8)\n",
    "data['is_79'] = (data['credit_sum'] % 100 == 79).astype(np.int8)\n",
    "data['is_9'] = (data['credit_sum'] % 10 == 9).astype(np.int8)\n",
    "data['is_8'] = (data['credit_sum'] % 10 == 8).astype(np.int8)\n",
    "data['is_0'] = (data['credit_sum'] % 10 == 0).astype(np.int8)\n",
    "data['is_7'] = (data['credit_sum'] % 10 == 7).astype(np.int8)\n",
    "data['is_1'] = (data['credit_sum'] % 10 == 1).astype(np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#One-hot для кол-ва месяцев, также частотность признака\n",
    "data['credit_month'] = data['credit_month'].astype(np.int8)\n",
    "credit_month_freq = data['credit_month'].value_counts(normalize=True).to_dict()\n",
    "data['credit_month_Freq'] = data['credit_month'].apply(lambda x: credit_month_freq[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#так как кодировка была плохая, то числа float были разделены запятой, а не точкой, поэтому pandas не определял их тип правильно\n",
    "data['score_shk'] = data['score_shk'].apply(lambda x: float(x.replace(',', '.')))\n",
    "data['score_shk_rare1'] = (data['score_shk'] <= data['score_shk'].quantile(0.01)).astype(np.int8)\n",
    "data['score_shk_rare99'] = (data['score_shk'] >= data['score_shk'].quantile(0.99)).astype(np.int8)\n",
    "data['score_shk'] = data['score_shk'].astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['age'] = data['age'].astype(np.int8)\n",
    "age_freq = data['age'].value_counts(normalize=True).to_dict()\n",
    "data['age_Freq'] = data['age'].apply(lambda x: age_freq[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#One-hot для дохода, также частотность признака\n",
    "data.loc[data[pd.isnull(data['monthly_income'])].index,'monthly_income'] = data['monthly_income'].mean()\n",
    "data['monthly_income'] = data['monthly_income'].astype(np.int32)\n",
    "data['incme_round1000'] = (data['monthly_income'] % 1000 == 0).astype(np.int8)\n",
    "data['incme_round100'] = (data['monthly_income'] % 100 == 0).astype(np.int8)\n",
    "data['incme_round10'] = (data['monthly_income'] % 10 == 0).astype(np.int8)\n",
    "monthly_income_freq = data['monthly_income'].value_counts(normalize=True).to_dict()\n",
    "data['monthly_income_Freq'] = data['monthly_income'].apply(lambda x: monthly_income_freq[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#были пропуски в credit_count и overdue_credit_count\n",
    "#для overdue_credit_count заполним модой, а для credit_count сделаем простую линейную регрессию\n",
    "#я что-то тогда был нубом, и не знал что  StandardScaler надо юзать для линейной регрессии, поэтому без StandardScaler\n",
    "# также добавлен is_nun -  признак был ли пропуск или не было \n",
    "data['is_nun'] = False\n",
    "data.loc[data[data['credit_count'].isnull()].index,'is_nun'] = True\n",
    "data['is_nun'] = data['is_nun'].astype(np.int8)\n",
    "data.loc[data[data['overdue_credit_count'].isnull()].index,'overdue_credit_count'] = data['overdue_credit_count'].quantile()\n",
    "data['overdue_credit_count'] = data['overdue_credit_count'].astype(np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/romankucev/anaconda/lib/python2.7/site-packages/scipy/linalg/basic.py:884: RuntimeWarning: internal gelsd driver lwork query error, required iwork dimension not returned. This is likely the result of LAPACK bug 0038, fixed in LAPACK 3.2.2 (released July 21, 2010). Falling back to 'gelss' driver.\n",
      "  warnings.warn(mesg, RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lr = LinearRegression()\n",
    "X = data.ix[~data['credit_count'].isnull(), ~data.columns.isin(['credit_count','living_region'])]\n",
    "y = data.ix[~data['credit_count'].isnull(), 'credit_count']\n",
    "lr.fit(X, y)\n",
    "v = lr.predict(data.ix[data['credit_count'].isnull(),~data.columns.isin(['credit_count','living_region'])])\n",
    "data.ix[data['credit_count'].isnull(), 'credit_count'] = v.astype(np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['credit_count'] = data['credit_count'].astype(np.int8)\n",
    "credit_count_freq = data['credit_count'].value_counts(normalize=True).to_dict()\n",
    "data['credit_count_Freq'] = data['credit_count'].apply(lambda x: credit_count_freq[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#вот тут я тупанул и скорее всего из-за этого не затащил конкурс(((\n",
    "#в данной задаче от написания региона зависит таргет, поэтому подобной нормализацией только ухудшаете ситуацию.\n",
    "#Точнее, этот столбец можно добавить дополнительно, вторым, но не вместо.\n",
    "# т е я \"почистил\" регионы, убив много информации\n",
    "region = data['living_region'].copy()\n",
    "region = region.str.encode(\"utf8\")\n",
    "region[region.isnull()] = 'Missing'\n",
    "region = region.str.replace('ОБЛ ', '')\n",
    "region = region.str.replace('КРАЙ ', '')\n",
    "region = region.str.replace('РЕСПУБЛИКА ', '')\n",
    "region = region.str.replace('РЕСП ', '')\n",
    "region = region.str.replace('ОБЛАСТЬ ', '')\n",
    "region = region.str.replace('ОБЛ ', '')\n",
    "region = region.str.replace(' КРАЙ', '')\n",
    "region = region.str.replace(' РЕСПУБЛИКА', '')\n",
    "region = region.str.replace(' РЕСП', '')\n",
    "region = region.str.replace(' ОБЛАСТЬ', '')\n",
    "region = region.str.replace(' ОБЛ', '')\n",
    "region = region.str.replace(' ГОРОД', '')\n",
    "region = region.str.replace(' Г', '')\n",
    "region = region.str.replace('РЕСП. ', '')\n",
    "region = region.str.replace(' Р-Н', '')\n",
    "region = region.str.replace(' АО', '')\n",
    "region = region.str.replace('Г. ', '')\n",
    "region = region.str.replace('ОБЛ. ', '')\n",
    "region = region.str.replace('ОБЛ.', '')\n",
    "region = region.str.replace('КРАЙ. ', '')\n",
    "region = region.str.replace(' АO', '')\n",
    "region = region.str.replace('АО ', '')\n",
    "region = region.str.replace('Г ', '')\n",
    "region = region.str.replace('98', 'САНКТ-ПЕТЕРБУРГ')\n",
    "region = region.str.replace('74', 'ЧЕЛЯБИНСКАЯ')\n",
    "region = region.str.replace('ОДИНЦОВО ', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in region.index:\n",
    "    region[i] = region[i].replace('Г.','')\n",
    "    region[i] = region[i].replace('РЕСП.','')\n",
    "    region[i] = region[i].replace('КРАЙ.','')\n",
    "    region[i] = region[i].replace('КАМЧАТС??ИЙ','КАМЧАТСКИЙ')\n",
    "    region[i] = region[i].replace('ХАНТЫ-МАНСИЙСКИЙ АВТОНОМНЫЙ ОКРУ- ЮГРА','ХАНТЫ-МАНСИЙСКИЙ')\n",
    "    region[i] = region[i].replace('ХАНТЫ-МАНСИЙСКИЙ АВТОНОМНЫЙ ОКРУ- Ю','ХАНТЫ-МАНСИЙСКИЙ')\n",
    "    region[i] = region[i].replace('ХАНТЫ-МАНСИЙСКИЙ-ЮГРА','ХАНТЫ-МАНСИЙСКИЙ')\n",
    "    region[i] = region[i].replace('САХА /ЯКУТИЯ/','САХА')\n",
    "    region[i] = region[i].replace('САХА (ЯКУТИЯ)','САХА')\n",
    "    region[i] = region[i].replace('СЕВ.','СЕВЕРНАЯ')\n",
    "    region[i] = region[i].replace('ЧУВАШСКАЯ - ЧУВАШИЯ','ЧУВАШИЯ ЧУВАШСКАЯ')\n",
    "    region[i] = region[i].replace('СЕВ.','СЕВЕРНАЯ')\n",
    "    region[i] = region[i].replace('ЕВРЕЙСКАЯБЛ','ЕВРЕЙСКАЯ АВТОНОМНАЯ')\n",
    "    region[i] = region[i].replace('АЕВРЕЙСКАЯ','ЕВРЕЙСКАЯ АВТОНОМНАЯ')\n",
    "    region[i] = region[i].replace('РОССИЯ','Missing')\n",
    "    region[i] = region[i].replace('МОСКВОСКАЯ','МОСКОВСКАЯ')\n",
    "    region[i] = region[i].replace('МЫТИЩИНСКИЙ','МОСКОВСКАЯ')\n",
    "    region[i] = region[i].replace('РЕСПУБЛИКАТАТАРСТАН','ТАТАРСТАН')\n",
    "    region[i] = region[i].replace('ЧУВАШИЯ ЧУВАШСКАЯ -','ЧУВАШИЯ ЧУВАШСКАЯ')\n",
    "    region[i] = region[i].replace('КАМЧАТСКАЯ','КАМЧАТСКИЙ')\n",
    "    region[i] = region[i].replace('ЧЕЛЯБИНСК','Missing')\n",
    "    region[i] = region[i].replace('ОРЁЛ','ОРЛОВСКАЯ')\n",
    "    region[i] = region[i].replace('ПРИВОЛЖСКИЙ ФЕДЕРАЛЬНЫЙ ОКРУГ','Missing')\n",
    "    region[i] = region[i].replace('БРЯНСКИЙ','БРЯНСКАЯ')\n",
    "    region[i] = region[i].replace('МОСКОВСКИЙ П','МОСКОВСКАЯ')\n",
    "    region[i] = region[i].replace('ЭВЕНКИЙСКИЙ','Missing')\n",
    "    region[i] = region[i].replace('ГУСЬ-ХРУСТАЛЬНЫЙ','Missing')\n",
    "    region[i] = region[i].replace('ДАЛЬНИЙ ВОСТОК','Missing')\n",
    "    region[i] = region[i].replace('ПЕРМСКАЯ','ПЕРМСКИЙ')\n",
    "    region[i] = region[i].replace('ЧУВАШИЯ ЧУВАШСКАЯ','ЧУВАШСКАЯ')\n",
    "    \n",
    "    if region[i][-1:] == '.':\n",
    "        region[i] = region[i][0:-1]\n",
    "data['living_region']  =  region  \n",
    "data['r_iy'] = data['living_region'].str.endswith('ИЙ').astype(np.int8)\n",
    "data['r_aya'] = data['living_region'].str.endswith('АЯ').astype(np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#ручками добавил в region.txt среднюю зарплату по регионам и добавил как фичу в данные\n",
    "#dat = pd.DataFrame()\n",
    "#dat['living_region'] = data['living_region'].value_counts().index\n",
    "#dat['count'] = ' '\n",
    "#dat.to_csv('region.txt',sep = ';')\n",
    "dat = pd.read_csv('region.txt',sep = ';',index_col = 1)\n",
    "dat['coun'] = dat['count'].apply(lambda x: float(x.replace(',', '.')))\n",
    "dat = dat['coun']\n",
    "data['salary_region'] = data['living_region'].apply(lambda x: dat[x])\n",
    "data['salary_region'] = data['salary_region'] * 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#также добавил кол-во населения в регионе\n",
    "dat = pd.DataFrame()\n",
    "#dat['living_region'] = data['living_region'].value_counts().index\n",
    "#dat['count'] = ' '\n",
    "#dat.to_csv('region_popular.txt',sep = ';')\n",
    "dat = pd.read_csv('region_popular.txt',sep = ';',index_col = 1)\n",
    "dat['coun'] = dat['count'].apply(lambda x: float(x.replace(',', '.')))\n",
    "dat = dat['coun']\n",
    "data['region_popular'] = data['living_region'].apply(lambda x: dat[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#средний процент взятых кредитов тинькова для каждого региона\n",
    "data['approval_rate'] = 0\n",
    "dtr = data[data['open_account_flg'] != -1]\n",
    "for txt in dtr['living_region'].value_counts().index:\n",
    "    data.loc[data[data['living_region'] == txt].index,'approval_rate']  = dtr[dtr['living_region'] == txt]['open_account_flg'].sum() / float(len(dtr[dtr['living_region'] == txt]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['credit_to_income'] = data['credit_sum'] / data['monthly_income']\n",
    "data['credit_to_income_m'] = data['credit_sum'] / (data['monthly_income'] * data['credit_month'])\n",
    "data['credit_to_salary_region'] = data['credit_sum'] / data['salary_region']\n",
    "data['income_to_salary_region'] = data['monthly_income'] / data['salary_region']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#one-hot для регионов, сначала хотел взять только самые частые регионы, а потом решли бинаризовать все регионы\n",
    "reg = data[u'living_region'].value_counts().index[:-1]\n",
    "for i in reg:\n",
    "    a = u'reg_' + str(i).decode(\"utf8\")\n",
    "    data[a] = (data[u'living_region'] == i).astype(np.int8)\n",
    "data[u'reg_other'] = False\n",
    "data.loc[(data[data[u'living_region'].isin(data[u'living_region'].value_counts().index[-1:])][u'reg_other'] == True).index,u'reg_other'] = True\n",
    "data[u'reg_other'] = data[u'reg_other'].astype(np.int8)\n",
    "del data['living_region']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#оптимизируем память\n",
    "for col in data.columns:\n",
    "    if set(data[col]) == set((0,1)):\n",
    "        data[col] = data[col].astype(np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del data['open_account_flg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_test = data[data['test'] == 1].copy()\n",
    "new_train = data[data['test'] == 0].copy()\n",
    "del new_test['test']\n",
    "del new_train['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_train.to_pickle('data/train_prep.pkl')\n",
    "new_test.to_pickle('data/test_prep.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
